{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Simple Step Counting Algorithm \n",
    "\n",
    "In this part, we will work with five traces of real accelerometer data, collected from Pixel 3 phone, to implement a simple step counting algorithm we talked about during class. The key goal is to give you some practices of working with sensor data, applying denosing methods, and extracting useful information. There are a total of four tasks, each with its own deliverables as specified below. At the end of this assignment, you will complete a simple step detection algorithm. Part of the learning is to understand the impact of the parameters on the information extraction efficiency, so try to play around with key parameters to get the step detection results as close as possible to the ground truth. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Prepartion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing dependencies\n",
    "We will need to install the following packages before we can import them below. Here we assume that you have already created a virtual environment and activated it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in ./.venv/lib/python3.13/site-packages (2.2.1)\n",
      "Requirement already satisfied: pandas in ./.venv/lib/python3.13/site-packages (2.2.3)\n",
      "Requirement already satisfied: matplotlib in ./.venv/lib/python3.13/site-packages (3.10.0)\n",
      "Requirement already satisfied: scipy in ./.venv/lib/python3.13/site-packages (1.14.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.13/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.13/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.13/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.13/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.13/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.13/site-packages (from matplotlib) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.13/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.13/site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in ./.venv/lib/python3.13/site-packages (from matplotlib) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./.venv/lib/python3.13/site-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install numpy pandas matplotlib scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import butter, filtfilt, find_peaks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we provide a function that can load the accelerometer data and convert the timestamp to human readable format. You are free to use it or write your own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "tags": [
     "test"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 796\n",
      "Sampling rate: 34.95 Hz\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-12-30 15:08:55.580000-05:00</td>\n",
       "      <td>0.209</td>\n",
       "      <td>-0.174</td>\n",
       "      <td>0.574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-12-30 15:08:55.610000-05:00</td>\n",
       "      <td>0.203</td>\n",
       "      <td>-0.358</td>\n",
       "      <td>0.766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-12-30 15:08:55.649000-05:00</td>\n",
       "      <td>-0.069</td>\n",
       "      <td>-0.279</td>\n",
       "      <td>-0.241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-12-30 15:08:55.864000-05:00</td>\n",
       "      <td>-0.183</td>\n",
       "      <td>-0.309</td>\n",
       "      <td>-0.335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-12-30 15:08:55.889000-05:00</td>\n",
       "      <td>0.303</td>\n",
       "      <td>-0.348</td>\n",
       "      <td>-0.042</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         timestamp      x      y      z\n",
       "0 2024-12-30 15:08:55.580000-05:00  0.209 -0.174  0.574\n",
       "1 2024-12-30 15:08:55.610000-05:00  0.203 -0.358  0.766\n",
       "2 2024-12-30 15:08:55.649000-05:00 -0.069 -0.279 -0.241\n",
       "3 2024-12-30 15:08:55.864000-05:00 -0.183 -0.309 -0.335\n",
       "4 2024-12-30 15:08:55.889000-05:00  0.303 -0.348 -0.042"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_accelerometer_data(file_path):\n",
    "    # Load the dataset\n",
    "    # Replace 'file_path' with the actual path to your accelerometer dataset\n",
    "    data = pd.read_csv(file_path, header=0, names=['timestamp', 'x', 'y', 'z'])\n",
    "\n",
    "    # Since we won't be using this function anywhere else, we will nest it here. \n",
    "    def convert_timestamp(data):\n",
    "        \"\"\"\n",
    "        Convert the timestamp to datetime format and set the correct timezone.\n",
    "        \"\"\"\n",
    "        data['timestamp'] = pd.to_datetime(data['timestamp'], unit='ms')\n",
    "        data['timestamp'] = data['timestamp'].dt.tz_localize('UTC').dt.tz_convert('US/Eastern')\n",
    "        return data\n",
    "    def analyze_accelerometer_data(data):        \n",
    "        # Calculate the number of samples\n",
    "        num_samples = data.shape[0]\n",
    "        \n",
    "        # Calculate the sampling rate\n",
    "        time_differences = data['timestamp'].diff().dropna()  # Time differences between consecutive samples\n",
    "        average_sampling_interval = time_differences.mean()  # Average time interval in milliseconds\n",
    "        sampling_rate = 1000 / average_sampling_interval if average_sampling_interval > 0 else float('inf')  # Convert interval to Hz\n",
    "        \n",
    "        return num_samples, sampling_rate\n",
    "    \n",
    "    \n",
    "    num_samples, sampling_rate = analyze_accelerometer_data(data)\n",
    "    print(f\"Number of samples: {num_samples}\")\n",
    "    print(f\"Sampling rate: {sampling_rate:.2f} Hz\")\n",
    "    \n",
    "    data = convert_timestamp(data)\n",
    "\n",
    "    return data, sampling_rate \n",
    "\n",
    "accelerometer_file = 'data/D5_lefthand_slow_circle_hop_20steps_linearaccelerometer.csv'\n",
    "data, sampling_rate = load_accelerometer_data(accelerometer_file)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: visualizing acceleration data \n",
    "\n",
    "In this first task, we will work with two real acceleration traces captured from a mobile device. Specifically, we will visualize the acceleration data along each of the three axes on a single figure to get a sense of how noisy they can be. \n",
    "\n",
    "\n",
    "For this task, you need to do the following: \n",
    "1. Write a function to plot the raw acceleration data.\n",
    "2. Generate two plots, one for `data/D1_lefthand_normal_20steps.csv` and the other for `data/D3_righthand_normal_20steps_linearaccelerometer.csv`. An example plot is shown below for the fifth trace D5.\n",
    "3. Answer the following questions. Based on your observation, and the official Andorid documentation on [sensor](https://developer.android.com/develop/sensors-and-location/sensors/sensors_motion#sensors-motion-accel) here:\n",
    "    1. What are the value ranges for the D1 trace and the D3 trace? \n",
    "    2. Why do you think the raw accelerometer data reading look different, given that they were collected under very similar conditions?\n",
    "\n",
    "<img src=\"figures/raw_acceleration_data.png\" width=800>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: visualize the magnitude of acceleration\n",
    "\n",
    "As we talked about in class, holding the phone in different orientations will lead to different x, y, z patterns as we saw above. To remove the impact of orientation, we will convert the acceleration data to the magnitude of acceleration. This is an easy way to design an orientation-independent algorithm for step detections. \n",
    "\n",
    "For this task, you need to do the following: \n",
    "1. Plot the magnitude of acceleration for traces D1 and D3. An example figure for the D5 trace is provided below.\n",
    "2. Compare the magnitude plots with the previous raw acceleration data plots, and briefly explain why it should be easier to work with the magnitude data.\n",
    "\n",
    "<img src=\"figures/magnitude_data.png\" width=800>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: denoising the magnitude data\n",
    "\n",
    "If we try to directly work on the raw magnitude data, we will find that the step detection algorithm result can be very off. To make it easy to work with the snesor data, it is a common practice to denoise the data. \n",
    "\n",
    "In this task, we will practice how to denoise the data by using a frequncy domain filter and a time domain filter. Specifically, we will use a frequency domain filter called a [butterworth filter](https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.butter.html) to remove noise. A Butterworth filter is a popular frequency domain lowpass filter that can remove high frequency noise while only letting the low frequencies through. In this task, we will use the Butterworth filter to construct a bandpass filter to only let through walking signal between 0.5Hz to 5Hz. We provide a code snippet for this filter below which you are free to use. \n",
    "\n",
    "```python\n",
    "# TODO: configure the filter\n",
    "# you will need to adjust it based on the trace your understanding from reading the documentation linked above\n",
    "order = 5 \n",
    "sampling_rate = 50.0 \n",
    "low_cutoff = 1 \n",
    "high_cuttoff = 2 \n",
    "\n",
    "# create the filter \n",
    "nyquist = 0.5 * sampling_rate\n",
    "low = low_cutoff / nyquist\n",
    "high = high_cutoff / nyquist\n",
    "b, a = butter(order, [low, high], btype='band', analog=False)\n",
    "\n",
    "# apply the filter on the data \n",
    "y = filtfilt(b, a, data)\n",
    "```\n",
    "\n",
    "For the time-domain filter, we will implement an expoential moving average filter. There are two key parameters to think about. The first is the window size and the second is the decaying factor.   \n",
    "- Window size: The window size determines how much smoothing is performed on the signal. As you increase the smoothing window, the signal will look cleaner and more visually pleasing, but beware of using too large a window since you will smooth out the important characteristics of the signal (for example, steps if you want to do step detection). Try increasing window size and see the effect.\n",
    "\n",
    "- Weights: Different averaging filters give different amounts of weight to the set of values that are aveeraged. The exponentially weighted moving average filter gives exponentially decreasing weights as the observation get older (i.e. recent observations are given relatively more weight than the older observations). This value is referred to as $\\alpha$ and commonly, alpha = 2 / (window_size + 1).\n",
    "\n",
    "\n",
    "For this task, you need to do the following:\n",
    "1. Create the bandpass filter and apply it to the raw magnitude data. \n",
    "2. Plot the filtered signal. An example figure for the D5 trace is provided below.\n",
    "3. Create the exponential moving average filter and apply it to the bandpass filtered data. If you are working with pandas, you can use the built-in [ewm](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.ewm.html) method.\n",
    "4. Plot the expoentially weighted smoothed signal. An example figure for the D5 trace is provided below.\n",
    "\n",
    "\n",
    "<img src=\"figures/bandpass_magnitude_data.png\" width=800>\n",
    "\n",
    "<img src=\"figures/exponeitally_smoothed_bandpass_magnitude_data.png\" width=800>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Step counting on filtered magnitude data\n",
    "\n",
    "From the filtered signal, determine the number of steps taken by the person. You can use one of the methods discussed in class or implement your own algorithm to do so. Plot the filtered signal and the detected steps.\n",
    "\n",
    "If you want to use the [`find_peaks` method](https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.find_peaks.html) for step detection, here are some useful information to know.\n",
    "\n",
    "The important parameters for this method are height, distance, prominence, and width, which you will need to properly set based on the signal.\n",
    "\n",
    "- Height: This threshold ensures only peaks exceeding a certain value are detected, helping to filter out minor fluctuations and zeroing in on significant movements.\n",
    "\n",
    "- Prominence: Useful in discerning genuine peaks from mere noise. A heightened prominence value ensures only peaks distinctly pronounced from their surroundings are identified. This precision is important for sidestepping minor data disturbances being misconceived as steps.\n",
    "\n",
    "- Distance: Crucial for step detection, the distance parameter corresponds to our understanding of the time lapse between two successive steps. For example, during regular walking, we usually register 1-2 steps every second. Adjusting the distance parameter helps in preventing the recognition of multiple peaks within a single stepâ€™s duration.\n",
    "\n",
    "- Width: The width parameter captures the full width of a peak at its half-prominence. This becomes particularly relevant in discerning between short spikes (possibly noise or artifacts) and genuine peaks of activity, like steps. In our context, width can reflect the typical duration of a step, and filtering peaks based on this duration can improve accuracy.\n",
    "\n",
    "For this task, answer the following questions:\n",
    "1. Report the number of steps detected for the D1 and D3 traces. \n",
    "2. Plot the signal and mark the points where your algorithm detects steps.  An example figure for the D5 trace is provided below.\n",
    "3. Run the code snippet below to generate the results for your step detection algorithm on all five traces. The output should be similar to the following. \n",
    "\n",
    "```text\n",
    "Total Step Count: 17\n",
    "        ID      Actual    Detected     Passed?\n",
    "         1          20          20        True\n",
    "         2          20          17       False\n",
    "         3          20          20        True\n",
    "         4          20          20        True\n",
    "         5          20          17       False\n",
    "```\n",
    "\n",
    "\n",
    "<img src=\"figures/step_detection_result.png\" width=800>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, re \n",
    "directory_path = \"data\"\n",
    "files = sorted(glob.glob(f\"{directory_path}/D*\"))\n",
    "\n",
    "results = []\n",
    "test_pass = False  \n",
    "\n",
    "for f in files:\n",
    "\n",
    "    #TODO: you will need to put everything together inside this step_detection_algorithm method\n",
    "    # which takes the raw data file, and return the number of detected steps\n",
    "    num_steps = step_detection_algorithm(f)\n",
    "    \n",
    "    # Parse filename to extract ID\n",
    "    match = re.search(r'D(\\d+)', f)\n",
    "    id = match.group(1)\n",
    "    \n",
    "    # Get ground truth\n",
    "    actual_steps = 20\n",
    "        \n",
    "    # Calculate accuracy       \n",
    "    if abs(num_steps - actual_steps) <=1:\n",
    "        test_pass = True\n",
    "    else: \n",
    "        test_pass = False \n",
    "\n",
    "    # Store results \n",
    "    results.append([id, actual_steps, num_steps, test_pass])\n",
    "    \n",
    "# Print table   \n",
    "print(\"{:>10}  {:>10}  {:>10}  {:>10}\".format('ID', 'Actual', 'Detected', 'Passed?'))\n",
    "for row in results:\n",
    "    print(\"{:>10}  {:>10}  {:>10}  {:>10}\".format(row[0], row[1], row[2], str(row[3])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
